{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0a82700ca695c337d9d37450a5cb4c7ff350a62784ad6b6b911049a3716c73c2c",
   "display_name": "Python 3.7.10 64-bit ('data_analysis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "인코딩 변환값 :  [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값 : ', labels)"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "print(labels)\n",
    "labels = labels.reshape(-1,1)\n",
    "print(labels)\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print(oh_labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 4 5 3 3 2 2]\n[[0]\n [1]\n [4]\n [5]\n [3]\n [3]\n [2]\n [2]]\n  (0, 0)\t1.0\n  (1, 1)\t1.0\n  (2, 4)\t1.0\n  (3, 5)\t1.0\n  (4, 3)\t1.0\n  (5, 3)\t1.0\n  (6, 2)\t1.0\n  (7, 2)\t1.0\n원-핫 인코딩 데이터\n[[1. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]]\n원-핫 인코딩 데이터 차원\n(8, 6)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature 들의 평균 값\nsepal length (cm)    5.843333\nsepal width (cm)     3.057333\npetal length (cm)    3.758000\npetal width (cm)     1.199333\ndtype: float64\n\n fearture 들의 분산 값\nsepal length (cm)    0.685694\nsepal width (cm)     0.189979\npetal length (cm)    3.116278\npetal width (cm)     0.581006\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns= iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\n fearture 들의 분산 값')\n",
    "print(iris_df.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature 들의 평균 값\nsepal length (cm)   -1.690315e-15\nsepal width (cm)    -1.842970e-15\npetal length (cm)   -1.698641e-15\npetal width (cm)    -1.409243e-15\ndtype: float64\n\n fearture 들의 분산 값\nsepal length (cm)    1.006711\nsepal width (cm)     1.006711\npetal length (cm)    1.006711\npetal width (cm)     1.006711\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns= iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\n fearture 들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature 들의 최소 값\nsepal length (cm)    0.0\nsepal width (cm)     0.0\npetal length (cm)    0.0\npetal width (cm)     0.0\ndtype: float64\n\n fearture 들의 최대 값\nsepal length (cm)    1.0\nsepal width (cm)     1.0\npetal length (cm)    1.0\npetal width (cm)     1.0\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns= iris.feature_names)\n",
    "print('feature 들의 최소 값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\n fearture 들의 최대 값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "원본 train_array 데이터:  [ 0  1  2  3  4  5  6  7  8  9 10]\nScale된 train_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터: ', np.round(train_array.reshape(-1),2))\n",
    "print('Scale된 train_array 데이터: ', np.round(train_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "원본 test_array 데이터:  [0 1 2 3 4 5]\nScale된 test_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print('원본 test_array 데이터: ', np.round(test_array.reshape(-1),2))\n",
    "print('Scale된 test_array 데이터: ', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "source": [
    "## 타이타닉 생존자 예측"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}